{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Function\n",
    "\n",
    "\n",
    "Energy function to solve the optimization problem of finding the **shortest path** between two nodes in a graph. This function combines multiple terms that impose constraints and objectives on the solution. Here is a general energy function for finding shortest paths without particularizing to a specific (orgin,destination) pair:\n",
    "\n",
    "$$\n",
    "F = \\frac{\\mu_1}{2} \\sum_{i=1}^n \\sum_{j=1}^n C_{ij} x_{ij} + \n",
    "    \\frac{\\mu_2}{2} \\sum_{i=1}^n \\left( \\sum_{j=1}^n x_{ij} - 1 \\right)^2 + \n",
    "    \\frac{\\mu_2}{2} \\sum_{j=1}^n \\left( \\sum_{i=1}^n x_{ij} - 1 \\right)^2 + \n",
    "    \\frac{\\mu_3}{2} \\sum_{i=1}^n \\sum_{j=1}^n x_{ij}(1 - x_{ij}) \n",
    "$$\n",
    "\n",
    "## Components of the Energy Function\n",
    "\n",
    "### 1. **Path Cost**\n",
    "$$\n",
    "\\frac{\\mu_1}{2} \\sum_{i=1}^n \\sum_{j=1}^n C_{ij} x_{ij}\n",
    "$$\n",
    "- **Description**: Minimizes the total cost of the path.\n",
    "- **Variables**:\n",
    "  - $C_{ij} $: Cost (or distance) between nodes $i$ and $j$.\n",
    "  - $x_{ij} $: Binary variable indicating if the path between $i $ and $j$ is part of the solution $( x_{ij} = 1 $) or not $( x_{ij} = 0 $).\n",
    "- **Purpose**: Encourges the selection of paths with lower cost.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Row constraints**\n",
    "$\n",
    "\\frac{\\mu_2}{2} \\sum_{i=1}^n \\left( \\sum_{j=1}^n x_{ij} - 1 \\right)^2\n",
    "$\n",
    "- **Description**: This term ensures that each node has exactly **one outgoing edge**.\n",
    "- **Variables**:\n",
    "  - $\\sum_{j=1}^n x_{ij} $: Represents number of outgoing edges from node $i$\n",
    "- **Purpose**: Penalize solutions in which a node has more than one outgoing edge or none.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Column constraints**\n",
    "$\n",
    "\\frac{\\mu_2}{2} \\sum_{j=1}^n \\left( \\sum_{i=1}^n x_{ij} - 1 \\right)^2\n",
    "$\n",
    "- **Description**: This term ensures that each node has exactly **one incoming edge**.\n",
    "- **Variables**:\n",
    "  - $\\sum_{i=1}^n x_{ij} $: Represents number of incoming edges to node $j$.\n",
    "- **Purpose**: Penalize solutions in which a node has more than one incoming edge or none. \n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Binariness constraint**\n",
    "$\n",
    "\\frac{\\mu_3}{2} \\sum_{i=1}^n \\sum_{j=1}^n x_{ij}(1 - x_{ij})\n",
    "$\n",
    "- **Description**: This term forces the variables $( x_{ij} $) to be binary (0 or 1).\n",
    "- **Variables**:\n",
    "  - $x_{ij} (1 - x_{ij}) $: This product is zero if $( x_{ij} $) is 0 or 1, but is positive if $( x_{ij} $) takes intermediate values.\n",
    "- **Purpose**: Penalize solutions in which $x_{ij} $ takes values other than 0 or 1.\n",
    "\n",
    "---\n",
    "\n",
    "## Parameters\n",
    "- $\\mu_1, \\mu_2, \\mu_3 $: Weights that balance the importance of each term in the energy function. \n",
    "  - $ \\mu_1 $: Prioritizes the minimization of the total cost of the path. \n",
    "  - $ \\mu_2 $: Emphasis on path validity. \n",
    "  - $ \\mu_3 $: Controls the binariness of the variables. \n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "Energy Function combines **strong** (like path validity) and **weak** (like cost minimization and binariness) constraints to: \n",
    "1. **Find a valid path**.\n",
    "2. **Minimize the total cost of the path**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## DATA PREPARATION\n",
    "Transform the adjacency matrix into a cost matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data from CSV file\n",
    "try:\n",
    "    df = pd.read_csv('../data/synthetic/synthetic_network.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found. Please check the file path.\")\n",
    "    exit()\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"Error: The file is empty or invalid.\")\n",
    "    exit()\n",
    "\n",
    "# Identify unique nodes and create a mapping for indices\n",
    "nodos = sorted(set(df['origin']).union(set(df['destination'])))\n",
    "node_to_index = {node: idx for idx, node in enumerate(nodos)}\n",
    "n = len(nodos)\n",
    "\n",
    "# Initialize the cost matrix with infinity\n",
    "cost_matrix = np.full((n, n), np.inf)\n",
    "\n",
    "\n",
    "# Set diagonal to 0 (self-costs)\n",
    "np.fill_diagonal(cost_matrix, 0)\n",
    "\n",
    "# Fill the cost matrix with the values from the CSV\n",
    "for _, row in df.iterrows():\n",
    "    try:\n",
    "        origen = row['origin']\n",
    "        destino = row['destination']\n",
    "        costo = float(row['weight'])\n",
    "        cost_matrix[node_to_index[origen], node_to_index[destino]] = costo\n",
    "    except KeyError:\n",
    "        print(\"Error: Missing columns 'origen', 'destino', or 'costo'.\")\n",
    "        exit()\n",
    "    except ValueError:\n",
    "        print(f\"Error: Invalid cost value on row {_}.\")\n",
    "        exit()\n",
    "\n",
    "# Display the cost matrix\n",
    "print(\"Cost Matrix:\")\n",
    "print(cost_matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## NEURAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "\n",
    "\n",
    "# Load, normalize and flatten the distance matrix, assigning a large value to infinity values\n",
    "cost_matrix = np.array(df.pivot(index='origin', columns='destination', values='weight').fillna(1e6))\n",
    "cost_matrix[cost_matrix == np.inf] = 1e12\n",
    "cost_matrix_normalized = (cost_matrix - np.min(cost_matrix)) / (np.max(cost_matrix) - np.min(cost_matrix) + 1e-6)\n",
    "cost_matrix_flat = cost_matrix_normalized.flatten()\n",
    "distance_matrix = cost_matrix_flat\n",
    "\n",
    "\n",
    "# Number of nodes\n",
    "n = distance_matrix.shape[0]\n",
    "print(\"Number of nodes:\", n)\n",
    "\n",
    "\n",
    "# Hyperparameters (weights for energy terms)\n",
    "mu1 = 1.0\n",
    "mu2 = 10.0\n",
    "mu3 = 10.0\n",
    "\n",
    "# Define the Hopfield Neural Network layer\n",
    "@register_keras_serializable()\n",
    "class HopfieldLayer(Layer):\n",
    "    def __init__(self, n, distance_matrix, **kwargs):\n",
    "        super(HopfieldLayer, self).__init__(**kwargs)\n",
    "        self.n = n\n",
    "        self.distance_matrix = tf.constant(distance_matrix, dtype=tf.float32)\n",
    "        self.x = self.add_weight(\n",
    "            name=\"x\", \n",
    "            shape=(n, n), \n",
    "            initializer=\"random_uniform\", \n",
    "            trainable=True\n",
    "        )\n",
    "        self.optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
    "        # Valid arcs\n",
    "        self.valid_arcs = tf.constant((self.distance_matrix.numpy() != 0).astype(np.float32), dtype=tf.float32)\n",
    "                                         \n",
    "    def energy(self):\n",
    "        path_cost = tf.reduce_sum(self.distance_matrix * self.x)\n",
    "        row_constraint = tf.reduce_sum(tf.square(tf.reduce_sum(self.x, axis=1) - 1))\n",
    "        col_constraint = tf.reduce_sum(tf.square(tf.reduce_sum(self.x, axis=0) - 1))\n",
    "        binary_constraint = tf.reduce_sum(tf.square(self.x * (1 - self.x)))\n",
    "        invalid_arcs_penalty = tf.reduce_sum(tf.square(self.x * (1 - self.valid_arcs)))\n",
    "        return (mu1/2)*path_cost + (mu2/2)*row_constraint + (mu2/2)*col_constraint + (mu3/2)*binary_constraint + 1000*invalid_arcs_penalty\t\n",
    "        \n",
    "    \n",
    "    def fine_tune_with_constraints(self, source, destination, iterations=500):\n",
    "        print(\"Initial Energy:\", self.energy().numpy())\n",
    "        for i in range(iterations):\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Fine-tune with source and destination constraints\n",
    "                source_out = tf.reduce_sum(self.x[source, :]) - 1\n",
    "                term5 = (10.0 / 2) * tf.square(source_out)\n",
    "\n",
    "                dest_in = tf.reduce_sum(self.x[:, destination]) - 1\n",
    "                term6 = (10.0 / 2) * tf.square(dest_in)\n",
    "\n",
    "                energy = self.energy() + term5 + term6\n",
    "\n",
    "            gradients = tape.gradient(energy, [self.x])\n",
    "            self.optimizer.apply_gradients(zip(gradients, [self.x]))\n",
    "            # Clip the variables to [0, 1] to enforce valid range\n",
    "            self.x.assign(tf.clip_by_value(self.x, 0.0, 1.0))\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Fine-Tuning Iteration {i}, Energy: {energy.numpy()}\")\n",
    "        print(\"Final Energy:\", self.energy().numpy())\n",
    "        return self.x\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        return self.x\n",
    "    \n",
    "    def compile(self, optimizer):\n",
    "        super(HopfieldLayer, self).compile()\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(HopfieldLayer, self).get_config()\n",
    "        config.update({\n",
    "            'n': self.n,\n",
    "            'distance_matrix': self.distance_matrix.numpy().tolist(),\n",
    "            'x': self.x.numpy().tolist(),\n",
    "            'valid_arcs': self.valid_arcs.numpy().tolist() \n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        x = config.pop('x')\n",
    "        distance_matrix = config.pop('distance_matrix')\n",
    "        instance = cls(distance_matrix=distance_matrix, **config)\n",
    "        instance.x.assign(tf.constant(x, dtype=tf.float32))  # Restore self.x from the configuration\n",
    "        valid_arcs = config.pop('valid_arcs')\n",
    "        instance.valid_arcs.assign(tf.constant(valid_arcs, dtype=tf.float32))  # Restore self.valid_arcs from the configuration\n",
    "        return instance\n",
    "\n",
    "#Integrate custom HopfieldLayer with Keras model\n",
    "@register_keras_serializable()\n",
    "class HopfieldModel(Model):\n",
    "    def __init__(self, n, distance_matrix, **kwargs):\n",
    "        super(HopfieldModel, self).__init__(**kwargs)\n",
    "        self.hopfield_layer = HopfieldLayer(n, distance_matrix)\n",
    "        self.optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Custom training logic\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Compute the energy as the loss\n",
    "            loss = self.hopfield_layer.energy()\n",
    "        # Compute gradients and apply updates\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        # Return the loss\n",
    "        return {\"loss\": loss}\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        # Forward pass\n",
    "        return self.hopfield_layer(inputs, training=training)\n",
    "    \n",
    "    def predict(self,source,destination):\n",
    "        self.hopfield_layer.fine_tune_with_constraints(source, destination)\n",
    "        # Retrieve the optimized state matrix\n",
    "        state_matrix = tf.round(self.hopfield_layer.x).numpy()\n",
    "\n",
    "        # Extract the shortest path based on the state matrix\n",
    "        def extract_path(state_matrix):\n",
    "            path = []\n",
    "            current_node = source\n",
    "            visited = set()\n",
    "\n",
    "            while current_node != destination:\n",
    "                path.append(current_node)\n",
    "                visited.add(current_node)\n",
    "                # Find the next node\n",
    "                next_node = np.argmax(state_matrix[current_node])\n",
    "                if next_node in visited or next_node == destination:\n",
    "                    break\n",
    "                current_node = next_node\n",
    "\n",
    "            path.append(destination)\n",
    "            return path\n",
    "\n",
    "        # Extract and return the predicted path\n",
    "        return extract_path(state_matrix)\n",
    "       \n",
    "    def get_config(self):\n",
    "        config = super(HopfieldModel, self).get_config()\n",
    "        config.update({\n",
    "            'n': self.hopfield_layer.n,\n",
    "            'distance_matrix': self.hopfield_layer.distance_matrix.numpy().tolist()\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "    \n",
    "  \n",
    "             \n",
    "# Create the model\n",
    "model = HopfieldModel(n, distance_matrix)\n",
    "# Compile the model with a custom optimizer\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n",
    "\n",
    "\n",
    "# Ensure distance_matrix is a valid tensor and reshape it to match the expected input shape\n",
    "m = int(sqrt(n))\n",
    "distance_matrix_tensor = tf.constant(distance_matrix, dtype=tf.float32)\n",
    "distance_matrix_tensor = tf.reshape(distance_matrix_tensor, (m, m))  \n",
    "distance_matrix_tensor = tf.reshape(distance_matrix_tensor, (1, m, m))  \n",
    "\n",
    "# Create dummy target data as it is required by the fit method\n",
    "dummy_target = tf.zeros((1, n, n), dtype=tf.float32)\n",
    "\n",
    "# Train the model to minimize the energy function\n",
    "model(dummy_target)\n",
    "model.fit(dummy_target, epochs=1000)\n",
    "model.summary()\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"../models/trained_model_without_source_dest.keras\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source and destination node restrictions\n",
    "\n",
    "**Term 5: Source Node Constraint**\n",
    "\n",
    "$\n",
    "\\left( \\sum_{j=1}^n x_{s,j} - 1 \\right)^2\n",
    "$\n",
    "\n",
    "- $x_{s,j}$: Binary decision variable for the edge from source node $s$ to node $j$.\n",
    "- Ensures that the source node $s$ has exactly one outgoing edge.\n",
    "\n",
    "**Term 6: Destination Node Constraint**\n",
    "\n",
    "$\n",
    "\\left( \\sum_{i=1}^n x_{i,d} - 1 \\right)^2\n",
    "$\n",
    "\n",
    "- $ x_{i,d} $: Binary decision variable for the edge from node $ i $ to the destination node $ d $.\n",
    "- Ensures that the destination node $ d $ has exactly one incoming edge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning with source and destination constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_node = 27\n",
    "destination_node = 5\n",
    "\n",
    "# Register the custom layer when loading the model\n",
    "with tf.keras.utils.custom_object_scope({'HopfieldModel': HopfieldModel, 'HopfieldLayer': HopfieldLayer}):\n",
    "    # Load the model with custom objects\n",
    "    loaded_model = tf.keras.models.load_model('../models/trained_model_without_source_dest.keras', custom_objects={'HopfieldModel': HopfieldModel, 'HopfieldLayer': HopfieldLayer})\n",
    "# Recompile the model with a new optimizer\n",
    "loaded_model.compile(optimizer=Adam(learning_rate=0.1))\n",
    "\n",
    "# Predict the shortest path from the source to the destination node\n",
    "path = loaded_model.predict(source_node, destination_node)\n",
    "print(\"Predicted Path:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost of the shortest path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cost of the shortest path\n",
    "# Adjusted to account for the real cost matrix (not normalized)\n",
    "def calculate_real_path_cost(real_cost_matrix, path):\n",
    "    cost = 0\n",
    "    for i in range(len(path) - 1):\n",
    "        cost += real_cost_matrix[path[i], path[i + 1]]\n",
    "    return cost\n",
    "\n",
    "path_cost = calculate_real_path_cost(cost_matrix, path)\n",
    "print(\"Cost of the Shortest Path (Real Costs):\", path_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the shortest path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualization of the shortest path using NetworkX\n",
    "def visualize_shortest_path(real_cost_matrix, shortest_path):\n",
    "    G = nx.DiGraph()\n",
    "    n = real_cost_matrix.shape[0]\n",
    "\n",
    "    # Add edges with weights\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if real_cost_matrix[i, j] < 1e6:  # Exclude large values (representing infinity)\n",
    "                G.add_edge(i, j, weight=real_cost_matrix[i, j])\n",
    "\n",
    "    # Generate positions for nodes\n",
    "    pos = nx.spring_layout(G)\n",
    "\n",
    "    # Draw the entire graph\n",
    "    nx.draw(G, pos, with_labels=True, node_color=\"lightblue\", node_size=500, edge_color=\"gray\")\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels={(i, j): f\"{d['weight']:.2f}\" for i, j, d in G.edges(data=True)})\n",
    "\n",
    "    # Highlight the shortest path\n",
    "    path_edges = [(shortest_path[i], shortest_path[i + 1]) for i in range(len(shortest_path) - 1)]\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=path_edges, edge_color=\"red\", width=2)\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=shortest_path, node_color=\"yellow\", node_size=700)\n",
    "\n",
    "    plt.title(\"Shortest Path Visualization\")\n",
    "    plt.show()\n",
    "\n",
    "visualize_shortest_path(cost_matrix, path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
